{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import text_data_load, text_data_split, text_data_loader\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "from src import seed_everything\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = argparse.Namespace()\n",
    "with open('config.json','rt') as f:\n",
    "    args.__dict__.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = np.load('data/text_vector/test_item_summary_vector.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129777,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_text_df = pd.DataFrame([item[0], item[1]]).T\n",
    "books_text_df.columns = ['isbn', 'item_summary_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_text_df['item_summary_vector'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_text_df['item_summary_vector'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_csv('data/users.csv')\n",
    "books = pd.read_csv('data/books.csv')\n",
    "test = pd.read_csv('data/test_ratings.csv')\n",
    "train = pd.read_csv('data/train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11676</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116866</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152827</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>0</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157969</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>0</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67958</td>\n",
       "      <td>0399135782</td>\n",
       "      <td>0</td>\n",
       "      <td>A Chinese immigrant who is convinced she is dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76694</th>\n",
       "      <td>278543</td>\n",
       "      <td>1576734218</td>\n",
       "      <td>0</td>\n",
       "      <td>On Becoming Childwise responds to this need by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76695</th>\n",
       "      <td>278563</td>\n",
       "      <td>3492223710</td>\n",
       "      <td>0</td>\n",
       "      <td>Respektlos macht der Autor mit der griechische...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76696</th>\n",
       "      <td>278633</td>\n",
       "      <td>1896095186</td>\n",
       "      <td>0</td>\n",
       "      <td>The fascinating characters in this short story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76697</th>\n",
       "      <td>278668</td>\n",
       "      <td>8408044079</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76698</th>\n",
       "      <td>278851</td>\n",
       "      <td>0767907566</td>\n",
       "      <td>0</td>\n",
       "      <td>A daring twist on the travel-adventure genre t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76699 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id        isbn  rating  \\\n",
       "0        11676  0002005018       0   \n",
       "1       116866  0002005018       0   \n",
       "2       152827  0060973129       0   \n",
       "3       157969  0374157065       0   \n",
       "4        67958  0399135782       0   \n",
       "...        ...         ...     ...   \n",
       "76694   278543  1576734218       0   \n",
       "76695   278563  3492223710       0   \n",
       "76696   278633  1896095186       0   \n",
       "76697   278668  8408044079       0   \n",
       "76698   278851  0767907566       0   \n",
       "\n",
       "                                                 summary  \n",
       "0      In a small town in Canada, Clara Callan reluct...  \n",
       "1      In a small town in Canada, Clara Callan reluct...  \n",
       "2      Here, for the first time in paperback, is an o...  \n",
       "3      Describes the great flu epidemic of 1918, an o...  \n",
       "4      A Chinese immigrant who is convinced she is dy...  \n",
       "...                                                  ...  \n",
       "76694  On Becoming Childwise responds to this need by...  \n",
       "76695  Respektlos macht der Autor mit der griechische...  \n",
       "76696  The fascinating characters in this short story...  \n",
       "76697                                                NaN  \n",
       "76698  A daring twist on the travel-adventure genre t...  \n",
       "\n",
       "[76699 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(test,books[['isbn','summary']],on='isbn')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29790"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['summary'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>4</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67544</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>7</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123629</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200273</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210926</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>9</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306790</th>\n",
       "      <td>278843</td>\n",
       "      <td>0743525493</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306791</th>\n",
       "      <td>278851</td>\n",
       "      <td>067161746X</td>\n",
       "      <td>6</td>\n",
       "      <td>A tongue-in-cheek survival guide for single pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306792</th>\n",
       "      <td>278851</td>\n",
       "      <td>0884159221</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306793</th>\n",
       "      <td>278851</td>\n",
       "      <td>0912333022</td>\n",
       "      <td>7</td>\n",
       "      <td>These hilarious stories by the creator of publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306794</th>\n",
       "      <td>278851</td>\n",
       "      <td>1569661057</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306795 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        isbn  rating  \\\n",
       "0             8  0002005018       4   \n",
       "1         67544  0002005018       7   \n",
       "2        123629  0002005018       8   \n",
       "3        200273  0002005018       8   \n",
       "4        210926  0002005018       9   \n",
       "...         ...         ...     ...   \n",
       "306790   278843  0743525493       7   \n",
       "306791   278851  067161746X       6   \n",
       "306792   278851  0884159221       7   \n",
       "306793   278851  0912333022       7   \n",
       "306794   278851  1569661057      10   \n",
       "\n",
       "                                                  summary  \n",
       "0       In a small town in Canada, Clara Callan reluct...  \n",
       "1       In a small town in Canada, Clara Callan reluct...  \n",
       "2       In a small town in Canada, Clara Callan reluct...  \n",
       "3       In a small town in Canada, Clara Callan reluct...  \n",
       "4       In a small town in Canada, Clara Callan reluct...  \n",
       "...                                                   ...  \n",
       "306790                                                NaN  \n",
       "306791  A tongue-in-cheek survival guide for single pe...  \n",
       "306792                                                NaN  \n",
       "306793  These hilarious stories by the creator of publ...  \n",
       "306794                                                NaN  \n",
       "\n",
       "[306795 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.merge(train,books[['isbn','summary']],on='isbn')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in books_text_df['item_summary_vector'].values:\n",
    "    if sum(i) == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "isbns = pd.concat([train['isbn'], test['isbn']]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2isbn = {idx:isbn for idx, isbn in enumerate(isbns)}\n",
    "isbn2idx = {isbn:idx for idx, isbn in idx2isbn.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129777"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isbn2idx['0671870432']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>item_summary_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129777</td>\n",
       "      <td>[0.063244164, 0.08317142, -0.20397493, 0.01717...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     isbn                                item_summary_vector\n",
       "4  129777  [0.063244164, 0.08317142, -0.20397493, 0.01717..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_text_df[books_text_df['isbn']==129777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129777"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books_text_df['item_summary_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factorize(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.linear1 = nn.Linear(768,self.dim)\n",
    "        self.linear2 = nn.Linear(self.dim,768)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.linear1(x)\n",
    "        x = self.linear2(emb)\n",
    "        return x, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "        self.eps = 1e-6\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y)+self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Dataset(Dataset):\n",
    "    def __init__(self, textcon):\n",
    "        self.textcon = textcon\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.textcon.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.textcon[i], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Factorize(16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = RMSELoss()\n",
    "\n",
    "data = Text_Dataset(books_text_df['item_summary_vector'].values)\n",
    "dataload = DataLoader(data,batch_size=1024,num_workers=0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Factorize(\n",
       "  (linear1): Linear(in_features=768, out_features=16, bias=True)\n",
       "  (linear2): Linear(in_features=16, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.85s/it, train_loss=0.111]\n"
     ]
    }
   ],
   "source": [
    "tk0 = tqdm.tqdm(range(1,11), smoothing=0, mininterval=1.0)\n",
    "loss_list = []\n",
    "for epoch in tk0:\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    n = 0\n",
    "    for i, data in enumerate(dataload):\n",
    "        data = data.to('cuda')\n",
    "        y,emb = model(data)\n",
    "        loss = criterion(y,data)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        n += 1\n",
    "    tk0.set_postfix(train_loss = total_loss/n)\n",
    "# train_loss 20epoch 0.111\n",
    "# test_loss 40~50 epoch 0.115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "n = 0\n",
    "emb_np = np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataload):\n",
    "        data = data.to('cuda')\n",
    "        y,emb = model(data)\n",
    "        total_loss += loss.item()\n",
    "        # print(emb_np.shape)\n",
    "        # print(emb.shape)\n",
    "        emb_np = np.concatenate((emb_np,emb.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_np = emb_np[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129777, 16)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/text_vector/train_item_summary_vector.npy',emb_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 129774, 129775, 129776], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_emb_train = np.array([books_text_df['isbn'].values,emb_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_emb = [i for i in emb_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_df = pd.DataFrame({'isbn':books_text_df['isbn'].values,'emb':list_emb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_vector = np.concatenate([\n",
    "    train_emb_df['isbn'].values.reshape(1,-1),\n",
    "    train_emb_df['emb'].values.reshape(1,-1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/text_vector/train_item_summary_vector.npy',train_emb_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_np = np.load('./data/text_vector/test_item_summary_vector.npy',allow_pickle=True)\n",
    "list_emb = [i for i in emb_np]\n",
    "train_emb_df = pd.DataFrame({'isbn':books_text_df['isbn'].values,'emb':list_emb})\n",
    "train_emb_vector = np.concatenate([\n",
    "    train_emb_df['isbn'].values.reshape(1,-1),\n",
    "    train_emb_df['emb'].values.reshape(1,-1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 52000)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/text_vector/test_item_summary_vector.npy',train_emb_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna FFDCN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import argparse\n",
    "import warnings\n",
    "import joblib\n",
    "from src import seed_everything\n",
    "\n",
    "from src.data import context_data_load, context_data_split, context_data_loader\n",
    "\n",
    "from src import FFDCNModel\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = argparse.Namespace()\n",
    "with open('config.json','rt') as f:\n",
    "    args.__dict__.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmdataset = context_data_load(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    seed_everything(args.SEED)\n",
    "    args.BATCH_SIZE = trial.suggest_categorical('BATCH_SIZE',[256, 512, 1024])\n",
    "    args.EPOCHS = 1 #trial.suggest_int('EPOCH',5,10)\n",
    "    args.LR = trial.suggest_loguniform('LR',0.001,0.01)\n",
    "    args.WEIGHT_DECAY = trial.suggest_loguniform('WEIGHT_DECAY',1e-07,5e-06)\n",
    "    args.FFM_EMBED_DIM = trial.suggest_int('FFM_EMBED_DIM', 3, 32)\n",
    "    args.DCN_EMBED_DIM = trial.suggest_int('DCN_EMBED_DIM', 1, 16)\n",
    "    DCN_MLP_DIM_LAYERS = trial.suggest_int('DCN_MLP_DIM_LAYERS',1,3)\n",
    "    args.DCN_MLP_DIMS = [trial.suggest_int('DCN_MLP_DIM_NUM',1,16)]*DCN_MLP_DIM_LAYERS\n",
    "    args.DCN_DROPOUT = trial.suggest_categorical(\"DCN_DROPOUT\",[0.2,0.25,0.3])\n",
    "    args.DCN_NUM_LAYERS = trial.suggest_int('DCN_NUM_LAYERS',1 , 4)\n",
    "    # args.USER_N_D = trial.suggest_int('USER_N_D',0,3)\n",
    "    # args.USER_F_D = trial.suggest_int('USER_N_F',3,6)\n",
    "    # args.ISBN_N_D = trial.suggest_categorical('ISBN_N_D',[12,14,16,18,20,22])\n",
    "    # args.ISBN_N_F = trial.suggest_int('ISBN_N_F',28,32)\n",
    "    # ffmdataset = context_data_load(args)\n",
    "    dataffm = context_data_split(args,ffmdataset)\n",
    "    dataffm = context_data_loader(args,dataffm)\n",
    "    model = FFDCNModel(args,dataffm)\n",
    "    model.train()\n",
    "    log_score = model.predict_train()\n",
    "    \n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=49)\n",
    "study = optuna.create_study(\n",
    "    study_name = 'FFDCN_parameter_opt',\n",
    "    direction = 'minimize',\n",
    "    sampler = sampler,\n",
    ")\n",
    "study.optimize(objective, n_trials=200)\n",
    "print(\"Best Score:\",study.best_value)\n",
    "print(\"Best trial\",study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BATCH_SIZE': 257,\n",
       " 'LR': 0.004801638061928483,\n",
       " 'WEIGHT_DECAY': 2.8409501258311365e-07,\n",
       " 'FFM_EMBED_DIM': 26,\n",
       " 'DCN_EMBED_DIM': 15,\n",
       " 'DCN_MLP_DIM_LAYERS': 1,\n",
       " 'DCN_MLP_DIM_NUM': 5,\n",
       " 'DCN_DROPOUT': 0.2,\n",
       " 'DCN_NUM_LAYERS': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.get_trials()[-1].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./valid/studysave1003.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study,'./valid/studysave1003.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./valid/studysave_NEW.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study,'./valid/studysave_NEW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jl = joblib.load('./valid/studysave1003.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BATCH_SIZE': 858,\n",
       " 'LR': 0.004313538772296255,\n",
       " 'WEIGHT_DECAY': 2.64921217501965e-07,\n",
       " 'FFM_EMBED_DIM': 25,\n",
       " 'DCN_EMBED_DIM': 6,\n",
       " 'DCN_MLP_DIM_LAYERS': 3,\n",
       " 'DCN_MLP_DIM_NUM': 1,\n",
       " 'DCN_DROPOUT': 0.25,\n",
       " 'DCN_NUM_LAYERS': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jl.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold for FFDCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import argparse\n",
    "import warnings\n",
    "import joblib\n",
    "from src import seed_everything\n",
    "\n",
    "from src.data import context_data_load, context_data_split, context_data_loader\n",
    "\n",
    "from src import FFDCNModel\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = argparse.Namespace()\n",
    "with open('config.json','rt') as f:\n",
    "    args.__dict__.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = context_data_load(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = []\n",
    "for train_idx, valid_idx in skf.split(data['train'].drop(['rating'], axis=1), data['train']['rating']):\n",
    "    folds.append((train_idx, valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1 ===============\n",
      "--------------- FFDCN TRAINING ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [00:27<00:00, 34.29it/s, loss=2.19]\n",
      "100%|██████████| 240/240 [00:01<00:00, 216.16it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: rmse: 2.1640109036934394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 205.61it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Saving Valid ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 219.25it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FFDCN PREDICT ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 228.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 2 ===============\n",
      "--------------- FFDCN TRAINING ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [00:27<00:00, 34.79it/s, loss=2.17]\n",
      "100%|██████████| 240/240 [00:01<00:00, 220.33it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: rmse: 2.165730645553602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 176.13it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Saving Valid ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 218.84it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FFDCN PREDICT ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 268.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 3 ===============\n",
      "--------------- FFDCN TRAINING ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [00:27<00:00, 34.61it/s, loss=2.17]\n",
      "100%|██████████| 240/240 [00:01<00:00, 213.14it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: rmse: 2.181752089298212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 200.99it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Saving Valid ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 218.17it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FFDCN PREDICT ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 263.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 4 ===============\n",
      "--------------- FFDCN TRAINING ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [00:28<00:00, 34.20it/s, loss=2.17]\n",
      "100%|██████████| 240/240 [00:01<00:00, 207.65it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: rmse: 2.160661193155635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 204.64it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Saving Valid ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 187.69it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FFDCN PREDICT ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 243.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 5 ===============\n",
      "--------------- FFDCN TRAINING ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [00:27<00:00, 34.69it/s, loss=2.17]\n",
      "100%|██████████| 240/240 [00:01<00:00, 184.72it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: rmse: 2.1739715771745107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 205.13it/s]\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Saving Valid ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:01<00:00, 219.58it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FFDCN PREDICT ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 263.98it/s]\n"
     ]
    }
   ],
   "source": [
    "ffdcn_predicts = []\n",
    "for fold in range(5):\n",
    "    seed_everything(42)\n",
    "    print('='*15,fold+1,'='*15)\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    # Fold i Data Split\n",
    "    X_train = data['train'].drop(['rating'], axis=1).iloc[train_idx]\n",
    "    X_valid = data['train'].drop(['rating'], axis=1).iloc[valid_idx]\n",
    "    y_train = data['train']['rating'][train_idx]\n",
    "    y_valid = data['train']['rating'][valid_idx]\n",
    "    # Create Fold i Dataloader\n",
    "    fold_data = {\n",
    "            'X_train':X_train,\n",
    "            'X_valid':X_valid,\n",
    "            'y_train':y_train,\n",
    "            'y_valid':y_valid,\n",
    "            'test':data['test'],\n",
    "            'field_dims':data['field_dims'],\n",
    "            'sub':data['sub'],\n",
    "            'idx2user':data['idx2user'],\n",
    "            'idx2isbn':data['idx2isbn']\n",
    "    }\n",
    "    fold_data = context_data_loader(args,fold_data)\n",
    "    # Create Fold i FFDCN Model and train\n",
    "    print(f'--------------- {args.MODEL} TRAINING ---------------')\n",
    "    model = FFDCNModel(args,fold_data)\n",
    "    model.train()\n",
    "    log_score = model.predict_train()\n",
    "\n",
    "    # Fold i Model's Predict Test data\n",
    "    print(f'--------------- {args.MODEL} PREDICT ---------------')\n",
    "    predicts = model.predict(fold_data['test_dataloader'])\n",
    "    ffdcn_predicts.append(predicts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- SAVE FFDCN PREDICT ---------------\n"
     ]
    }
   ],
   "source": [
    "# Fold i Save Predicted test data\n",
    "print(f'--------------- SAVE {args.MODEL} PREDICT ---------------')\n",
    "submission = pd.read_csv(args.DATA_PATH + 'sample_submission.csv')\n",
    "for fold_predict in ffdcn_predicts:\n",
    "    submission['rating'] += np.array(fold_predict) / 5\n",
    "\n",
    "now = time.localtime()\n",
    "now_date = time.strftime('%Y%m%d', now)\n",
    "now_hour = time.strftime('%X', now)\n",
    "save_time = now_date + '_' + now_hour.replace(':', '')\n",
    "submission.to_csv('submit/5fold_{}_{}.csv'.format(save_time, args.MODEL), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
