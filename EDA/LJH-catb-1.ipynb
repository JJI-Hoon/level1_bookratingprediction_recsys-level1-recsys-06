{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tqdm\n",
    "import pdb\n",
    "from scipy.sparse import csr_matrix, linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users shape:  (68092, 3)\n",
      "books shape:  (149570, 10)\n",
      "train_ratings shape:  (306795, 3)\n"
     ]
    }
   ],
   "source": [
    "path= '/opt/ml/level1_bookratingprediction_recsys-level1-recsys-06/data/'\n",
    "\n",
    "users = pd.read_csv(path+'users.csv')\n",
    "books = pd.read_csv(path+'books.csv')\n",
    "train_ratings = pd.read_csv(path+'train_ratings.csv')\n",
    "test_ratings = pd.read_csv(path+'test_ratings.csv')\n",
    "submit = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "print('users shape: ', users.shape)\n",
    "print('books shape: ', books.shape)\n",
    "print('train_ratings shape: ', train_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(real: list, predict: list) -> float:\n",
    "    pred = np.array(predict)\n",
    "    return np.sqrt(np.mean((real-pred) ** 2))\n",
    "\n",
    "SEED = 42\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['location_city'] = users['location'].apply(lambda x: x.split(',')[0])\n",
    "users['location_state'] = users['location'].apply(lambda x: x.split(',')[1])\n",
    "users['location_country'] = users['location'].apply(lambda x: x.split(',')[2])\n",
    "users = users.drop(['location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.concat([train_ratings, test_ratings]).reset_index(drop=True)\n",
    "context_df = ratings.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')\n",
    "train_df = train_ratings.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')\n",
    "test_df = test_ratings.merge(users, on='user_id', how='left').merge(books[['isbn', 'category', 'publisher', 'language', 'book_author']], on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_city2idx = {v:k for k,v in enumerate(context_df['location_city'].unique())}\n",
    "loc_state2idx = {v:k for k,v in enumerate(context_df['location_state'].unique())}\n",
    "loc_country2idx = {v:k for k,v in enumerate(context_df['location_country'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['location_city'] = train_df['location_city'].map(loc_city2idx)\n",
    "train_df['location_state'] = train_df['location_state'].map(loc_state2idx)\n",
    "train_df['location_country'] = train_df['location_country'].map(loc_country2idx)\n",
    "\n",
    "test_df['location_city'] = test_df['location_city'].map(loc_city2idx)\n",
    "test_df['location_state'] = test_df['location_state'].map(loc_state2idx)\n",
    "test_df['location_country'] = test_df['location_country'].map(loc_country2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_map(x: int) -> int:\n",
    "    x = int(x)\n",
    "    if x < 20:\n",
    "        return 1\n",
    "    elif x >= 20 and x < 30:\n",
    "        return 2\n",
    "    elif x >= 30 and x < 40:\n",
    "        return 3\n",
    "    elif x >= 40 and x < 50:\n",
    "        return 4\n",
    "    elif x >= 50 and x < 60:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['age'] = train_df['age'].fillna(int(train_df['age'].mean()))\n",
    "train_df['age'] = train_df['age'].apply(age_map)\n",
    "test_df['age'] = test_df['age'].fillna(int(test_df['age'].mean()))\n",
    "test_df['age'] = test_df['age'].apply(age_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "category2idx = {v:k for k,v in enumerate(context_df['category'].unique())}\n",
    "publisher2idx = {v:k for k,v in enumerate(context_df['publisher'].unique())}\n",
    "language2idx = {v:k for k,v in enumerate(context_df['language'].unique())}\n",
    "author2idx = {v:k for k,v in enumerate(context_df['book_author'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['category'] = train_df['category'].map(category2idx)\n",
    "train_df['publisher'] = train_df['publisher'].map(publisher2idx)\n",
    "train_df['language'] = train_df['language'].map(language2idx)\n",
    "train_df['book_author'] = train_df['book_author'].map(author2idx)\n",
    "\n",
    "test_df['category'] = test_df['category'].map(category2idx)\n",
    "test_df['publisher'] = test_df['publisher'].map(publisher2idx)\n",
    "test_df['language'] = test_df['language'].map(language2idx)\n",
    "test_df['book_author'] = test_df['book_author'].map(author2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id'] = train_df['user_id'].copy()\n",
    "test_df['id'] = test_df['user_id'].copy()\n",
    "\n",
    "train_df['bn'] = train_df['isbn'].copy()\n",
    "test_df['bn'] = test_df['isbn'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate (list(train_df.columns)) :\n",
    "    ca = i[1]\n",
    "    train_df[ca] = train_df[ca].astype('str')\n",
    "    test_df[ca] = test_df[ca].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 306795 entries, 0 to 306794\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   user_id           306795 non-null  object\n",
      " 1   isbn              306795 non-null  object\n",
      " 2   rating            306795 non-null  object\n",
      " 3   age               306795 non-null  object\n",
      " 4   location_city     306795 non-null  object\n",
      " 5   location_state    306795 non-null  object\n",
      " 6   location_country  306795 non-null  object\n",
      " 7   category          306795 non-null  object\n",
      " 8   publisher         306795 non-null  object\n",
      " 9   language          306795 non-null  object\n",
      " 10  book_author       306795 non-null  object\n",
      " 11  id                306795 non-null  object\n",
      " 12  bn                306795 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 32.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/computation/expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    240\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/computation/expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     69\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 32\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     24\u001b[0m     train_x,\n\u001b[1;32m     25\u001b[0m     train_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m cat_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_x)\n\u001b[0;32m---> 32\u001b[0m log_score \u001b[38;5;241m=\u001b[39m \u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [20], line 3\u001b[0m, in \u001b[0;36mrmse\u001b[0;34m(real, predict)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrmse\u001b[39m(real: \u001b[38;5;28mlist\u001b[39m, predict: \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m      2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predict)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean((\u001b[43mreal\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mpred\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/arraylike.py:110\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__sub__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__sub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49msub)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py:6259\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[1;32m   6258\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[0;32m-> 6259\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/base.py:1325\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1322\u001b[0m rvalues \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[1;32m   1324\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1325\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[1;32m   1327\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:226\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    222\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[1;32m    224\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:172\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    168\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m         result \u001b[39m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:110\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[39m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m--> 110\u001b[0m         result[mask] \u001b[39m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[1;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "params_cat = {\n",
    "        \"task_type\" : \"GPU\",\n",
    "        \"devices\" : '0',\n",
    "        \"random_state\": SEED,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"n_estimators\": 2000,\n",
    "        \"verbose\" : 1,\n",
    "        \"objective\" : \"RMSE\",\n",
    "        \"max_depth\": 8,#trial.suggest_int(\"max_depth\", 1, 16),\n",
    "        \"colsample_bylevel\": 1,#trial.suggest_float(\"colsample_bylevel\", 0.8, 1.0),\n",
    "        #\"subsample\": 0.8, #trial.suggest_float(\"subsample\", 0.3, 1.0), GPU 사용시 안될수도.\n",
    "        \"min_child_samples\": 50, #trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"max_bin\": 300, #trial.suggest_int(\"max_bin\", 200, 500),\n",
    "        \"cat_features\" : list(train_df.drop(['rating','user_id','isbn'], axis =1).columns),\n",
    "        \"one_hot_max_size\" : 10\n",
    "}\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_df.drop(['rating','user_id','isbn'], axis = 1), train_df['rating'], test_size=0.2)\n",
    "\n",
    "model = CatBoostRegressor(**params_cat)\n",
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=[(val_x, val_y)],\n",
    "    #early_stopping_rounds=10,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "cat_pred = model.predict(val_x)\n",
    "log_score = rmse(val_y, cat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 306795 entries, 0 to 306794\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   user_id           306795 non-null  object\n",
      " 1   isbn              306795 non-null  object\n",
      " 2   rating            306795 non-null  object\n",
      " 3   age               306795 non-null  object\n",
      " 4   location_city     306795 non-null  object\n",
      " 5   location_state    306795 non-null  object\n",
      " 6   location_country  306795 non-null  object\n",
      " 7   category          306795 non-null  object\n",
      " 8   publisher         306795 non-null  object\n",
      " 9   language          306795 non-null  object\n",
      " 10  book_author       306795 non-null  object\n",
      " 11  id                306795 non-null  object\n",
      " 12  bn                306795 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 32.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15800\n",
      "[LightGBM] [Info] Number of data points in the train set: 245436, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 7.068747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.35352\n",
      "[200]\tvalid_0's rmse: 2.3377\n",
      "[300]\tvalid_0's rmse: 2.32986\n",
      "[400]\tvalid_0's rmse: 2.32636\n",
      "[500]\tvalid_0's rmse: 2.3213\n",
      "[600]\tvalid_0's rmse: 2.3167\n",
      "[700]\tvalid_0's rmse: 2.31337\n",
      "[800]\tvalid_0's rmse: 2.31196\n",
      "[900]\tvalid_0's rmse: 2.30973\n",
      "[1000]\tvalid_0's rmse: 2.30709\n",
      "[1100]\tvalid_0's rmse: 2.30593\n",
      "[1200]\tvalid_0's rmse: 2.30512\n",
      "[1300]\tvalid_0's rmse: 2.30456\n",
      "[1400]\tvalid_0's rmse: 2.30326\n",
      "[1500]\tvalid_0's rmse: 2.30175\n",
      "[1600]\tvalid_0's rmse: 2.30064\n",
      "[1700]\tvalid_0's rmse: 2.29969\n",
      "[1800]\tvalid_0's rmse: 2.29941\n",
      "[1900]\tvalid_0's rmse: 2.2985\n",
      "[2000]\tvalid_0's rmse: 2.2978\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1986]\tvalid_0's rmse: 2.2977\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(test_df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misbn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m      3\u001b[0m submit[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(test_df.drop(['user_id', 'isbn', 'rating'],axis = 1))\n",
    "test_df['rating'] = pred\n",
    "submit['rating'] = test['rating']\n",
    "submit.to_csv('../data/20221027_Catboost_Plueid_real.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
